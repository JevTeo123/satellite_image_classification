{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import imageio as iio\n",
    "import cv2\n",
    "\n",
    "# Keras Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5631 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "data = tf.keras.utils.image_dataset_from_directory(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iterator = data.as_numpy_iterator()\n",
    "batch = data_iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number represents numpy array of images and the labels\n",
    "scaled = batch[0]/255 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. PreProcess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(lambda x, y: (x/255, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_iterator = data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94509804"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_iterator.next()[0].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(data) * .7)\n",
    "val_size = int(len(data) *.2) + 1\n",
    "test_size = int(len(data) *.1) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.take(train_size)\n",
    "test = data.take(test_size)\n",
    "val = data.take(val_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Deep Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Build Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Jevan\\.conda\\envs\\traffic_image_classification\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Jevan\\.conda\\envs\\traffic_image_classification\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.add(Conv2D(16, (3, 3), 1, activation = \"relu\", input_shape = (256, 256, 3)))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), 1, activation = \"relu\"))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), 1, activation = \"relu\"))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dense(4, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\"adam\", loss = \"sparse_categorical_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 254, 254, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 127, 127, 16)      0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 125, 125, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 62, 62, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 60, 60, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 30, 30, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 57600)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               14745856  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 1028      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14770468 (56.34 MB)\n",
      "Trainable params: 14770468 (56.34 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = \"logs\"\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Jevan\\.conda\\envs\\traffic_image_classification\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Jevan\\.conda\\envs\\traffic_image_classification\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "123/123 [==============================] - 45s 359ms/step - loss: 0.4066 - accuracy: 0.8194 - val_loss: 0.1701 - val_accuracy: 0.9358\n",
      "Epoch 2/20\n",
      "123/123 [==============================] - 43s 347ms/step - loss: 0.2216 - accuracy: 0.8989 - val_loss: 0.1773 - val_accuracy: 0.9253\n",
      "Epoch 3/20\n",
      "123/123 [==============================] - 46s 373ms/step - loss: 0.1788 - accuracy: 0.9207 - val_loss: 0.1861 - val_accuracy: 0.9253\n",
      "Epoch 4/20\n",
      "123/123 [==============================] - 52s 422ms/step - loss: 0.1931 - accuracy: 0.9090 - val_loss: 0.1464 - val_accuracy: 0.9358\n",
      "Epoch 5/20\n",
      "123/123 [==============================] - 48s 388ms/step - loss: 0.1687 - accuracy: 0.9167 - val_loss: 0.2538 - val_accuracy: 0.8958\n",
      "Epoch 6/20\n",
      "123/123 [==============================] - 50s 405ms/step - loss: 0.1706 - accuracy: 0.9271 - val_loss: 0.2062 - val_accuracy: 0.9028\n",
      "Epoch 7/20\n",
      "123/123 [==============================] - 48s 387ms/step - loss: 0.1631 - accuracy: 0.9266 - val_loss: 0.1397 - val_accuracy: 0.9323\n",
      "Epoch 8/20\n",
      "123/123 [==============================] - 47s 383ms/step - loss: 0.1570 - accuracy: 0.9284 - val_loss: 0.2275 - val_accuracy: 0.8906\n",
      "Epoch 9/20\n",
      "123/123 [==============================] - 49s 392ms/step - loss: 0.1536 - accuracy: 0.9291 - val_loss: 0.1334 - val_accuracy: 0.9436\n",
      "Epoch 10/20\n",
      "123/123 [==============================] - 49s 392ms/step - loss: 0.1410 - accuracy: 0.9390 - val_loss: 0.1650 - val_accuracy: 0.9262\n",
      "Epoch 11/20\n",
      "123/123 [==============================] - 48s 391ms/step - loss: 0.1536 - accuracy: 0.9294 - val_loss: 0.1216 - val_accuracy: 0.9523\n",
      "Epoch 12/20\n",
      "123/123 [==============================] - 47s 383ms/step - loss: 0.1743 - accuracy: 0.9225 - val_loss: 0.1386 - val_accuracy: 0.9470\n",
      "Epoch 13/20\n",
      "123/123 [==============================] - 52s 422ms/step - loss: 0.1368 - accuracy: 0.9413 - val_loss: 0.1347 - val_accuracy: 0.9418\n",
      "Epoch 14/20\n",
      "123/123 [==============================] - 60s 485ms/step - loss: 0.1236 - accuracy: 0.9456 - val_loss: 0.1758 - val_accuracy: 0.9236\n",
      "Epoch 15/20\n",
      "123/123 [==============================] - 77s 622ms/step - loss: 0.1704 - accuracy: 0.9367 - val_loss: 0.7767 - val_accuracy: 0.8498\n",
      "Epoch 16/20\n",
      "123/123 [==============================] - 66s 534ms/step - loss: 0.2162 - accuracy: 0.9065 - val_loss: 0.1452 - val_accuracy: 0.9332\n",
      "Epoch 17/20\n",
      "123/123 [==============================] - 50s 405ms/step - loss: 0.1560 - accuracy: 0.9299 - val_loss: 0.1761 - val_accuracy: 0.9245\n",
      "Epoch 18/20\n",
      "123/123 [==============================] - 51s 415ms/step - loss: 0.1588 - accuracy: 0.9337 - val_loss: 0.1417 - val_accuracy: 0.9332\n",
      "Epoch 19/20\n",
      "123/123 [==============================] - 48s 390ms/step - loss: 0.1459 - accuracy: 0.9395 - val_loss: 0.1134 - val_accuracy: 0.9523\n",
      "Epoch 20/20\n",
      "123/123 [==============================] - 49s 395ms/step - loss: 0.1341 - accuracy: 0.9449 - val_loss: 0.1137 - val_accuracy: 0.9549\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(train, epochs = 20, validation_data=val, callbacks = [tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Images Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_photo(image_dir):\n",
    "    img = iio.imread(image_dir)\n",
    "    img = cv2.resize(img, (256, 256), interpolation=cv2.INTER_AREA)\n",
    "    prediction = model.predict(np.array([img / 255]))\n",
    "    label_map = {0: \"Cloudy\", 1: \"Desert\", 2:\"Green Area\", 3:\"Water\"}\n",
    "    label = prediction.argmax()\n",
    "    print(label_map.get(label))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step\n",
      "desert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jevan\\AppData\\Local\\Temp\\ipykernel_23036\\1166731189.py:2: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  img = iio.imread(image_dir)\n"
     ]
    }
   ],
   "source": [
    "predict_photo(\"C:/traffic_sign_image_classification/satellite_desert.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "traffic_image_classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
